### 简单介绍进程和线程以及它们的区别             

- 一个程序至少有一个进程，一个进程至少有一个线程

- 线程的划分尺度小于进程，使得多线程程序的并发性高

- 地址空间：同一进程的线程共享本进程的地址空间，而进程之间则是独立的地址空间。
- 资源拥有：同一进程内的线程共享本进程的资源如内存、I/O、cpu等，但是进程之间的资源是独立的。

- 一个进程崩溃后，在保护模式下不会对其他进程产生影响，但是一个线程崩溃整个进程都死掉。所以多进程要比多线程健壮。

- 进程切换时，消耗的资源大，效率高。所以涉及到频繁的切换时，使用线程要好于进程。同样如果要求同时进行并且又要共享某些变量的并发操作，只能用线程不能用进程

- 执行过程：每个独立的进程程有一个程序运行的入口、顺序执行序列和程序入口。但是线程不能独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制。
- 线程是处理器调度的基本单位，但是进程不是。
- 两者均可并发执行。

**优缺点：**

　　线程执行开销小，但是不利于资源的管理和保护。线程适合在SMP机器（双CPU系统）上运行。

　　进程执行开销大，但是能够很好的进行资源管理和保护。进程可以跨机器前移。

**何时使用多进程，何时使用多线程？**

对资源的管理和保护要求高，不限制开销和效率时，使用多进程。

要求效率高，频繁切换时，资源的保护管理要求不是很高时，使用多线程。

### 操作系统中进程调度策略有哪几种？             

 	FCFS(先来先服务)，优先级，时间片轮转，多级反馈 

**一、先来先服务和短作业(进程)优先调度算法**

**1．先来先服务调度算法**

先来先服务(FCFS)调度[算法](http://lib.csdn.net/base/datastructure)是一种最简单的调度算法，该算法既可用于作业调度，也可用于进程调度。当在作业调度中采用该算法时，每次调度都是从后备作业队列中选择一个或多个最先进入该队列的作业，将它们调入内存，为它们分配资源、创建进程，然后放入就绪队列。在进程调度中采用FCFS算法时，则每次调度是从就绪队列中选择一个最先进入该队列的进程，为之分配处理机，使之投入运行。该进程一直运行到完成或发生某事件而阻塞后才放弃处理机。

**2．短作业(进程)优先调度算法**

短作业(进程)优先调度算法SJ(P)F，是指对短作业或短进程优先调度的算法。它们可以分别用于作业调度和进程调度。短作业优先(SJF)的调度算法是从后备队列中选择一个或若干个估计运行时间最短的作业，将它们调入内存运行。而短进程优先(SPF)调度算法则是从就绪队列中选出一个估计运行时间最短的进程，将处理机分配给它，使它立即执行并一直执行到完成，或发生某事件而被阻塞放弃处理机时再重新调度。

**二、高优先权优先调度算法**

**1．优先权调度算法的类型**

为了照顾紧迫型作业，使之在进入系统后便获得优先处理，引入了最高优先权优先(FPF)调度算法。此算法常被用于批处理系统中，作为作业调度算法，也作为多种[操作系统](http://www.wypblog.com/archives/category/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F)中的进程调度算法，还可用于实时系统中。当把该算法用于作业调度时，系统将从后备队列中选择若干个优先权最高的作业装入内存。当用于进程调度时，该算法是把处理机分配给就绪队列中优先权最高的进程，这时，又可进一步把该算法分成如下两种。

1) 非抢占式优先权算法

在这种方式下，系统一旦把处理机分配给就绪队列中优先权最高的进程后，该进程便一直执行下去，直至完成；或因发生某事件使该进程放弃处理机时，系统方可再将处理机重新分配给另一优先权最高的进程。这种调度算法主要用于批处理系统中；也可用于某些对实时性要求不严的实时系统中。

2) 抢占式优先权调度算法

在这种方式下，系统同样是把处理机分配给优先权最高的进程，使之执行。但在其执行期间，只要又出现了另一个其优先权更高的进程，进程调度程序就立即停止当前进程(原优先权最高的进程)的执行，重新将处理机分配给新到的优先权最高的进程。因此，在采用这种调度算法时，是每当系统中出现一个新的就绪进程i  时，就将其优先权Pi与正在执行的进程j  的优先权Pj进行比较。如果Pi≤Pj，原进程Pj便继续执行；但如果是Pi>Pj，则立即停止Pj的执行，做进程切换，使i  进程投入执行。显然，这种抢占式的优先权调度算法能更好地满足紧迫作业的要求，故而常用于要求比较严格的实时系统中，以及对性能要求较高的批处理和分时系统中。

**2．高响应比优先调度算法**

在批处理系统中，短作业优先算法是一种比较好的算法，其主要的不足之处是长作业的运行得不到保证。如果我们能为每个作业引入前面所述的动态优先权，并使作业的优先级随着等待时间的增加而以速率a  提高，则长作业在等待一定的时间后，必然有机会分配到处理机。该优先权的变化规律可描述为：

(1) 如果作业的等待时间相同，则要求服务的时间愈短，其优先权愈高，因而该算法有利于短作业。

(2) 当要求服务的时间相同时，作业的优先权决定于其等待时间，等待时间愈长，其优先权愈高，因而它实现的是先来先服务。

(3)  对于长作业，作业的优先级可以随等待时间的增加而提高，当其等待时间足够长时，其优先级便可升到很高，从而也可获得处理机。简言之，该算法既照顾了短作业，又考虑了作业到达的先后次序，不会使长作业长期得不到服务。因此，该算法实现了一种较好的折衷。当然，在利用该算法时，每要进行调度之前，都须先做响应比的计算，这会增加系统开销。

**三、基于时间片的轮转调度算法**

**1．时间片轮转法**

1) 基本原理

在早期的时间片轮转法中，系统将所有的就绪进程按先来先服务的原则排成一个队列，每次调度时，把CPU  分配给队首进程，并令其执行一个时间片。时间片的大小从几ms  到几百ms。当执行的时间片用完时，由一个计时器发出时钟中断请求，调度程序便据此信号来停止该进程的执行，并将它送往就绪队列的末尾；然后，再把处理机分配给就绪队列中新的队首进程，同时也让它执行一个时间片。这样就可以保证就绪队列中的所有进程在一给定的时间内均能获得一时间片的处理机执行时间。换言之，系统能在给定的时间内响应所有用户的请求。

**2．多级反馈队列调度算法**

前面介绍的各种用作进程调度的算法都有一定的局限性。如短进程优先的调度算法，仅照顾了短进程而忽略了长进程，而且如果并未指明进程的长度，则短进程优先和基于进程长度的抢占式调度算法都将无法使用。而多级反馈队列调度算法则不必事先知道各种进程所需的执行时间，而且还可以满足各种类型进程的需要，因而它是目前被公认的一种较好的进程调度算法。在采用多级反馈队列调度算法的系统中，调度算法的实施过程如下所述。

(1)  应设置多个就绪队列，并为各个队列赋予不同的优先级。第一个队列的优先级最高，第二个队列次之，其余各队列的优先权逐个降低。该算法赋予各个队列中进程执行时间片的大小也各不相同，在优先权愈高的队列中，为每个进程所规定的执行时间片就愈小。例如，第二个队列的时间片要比第一个队列的时间片长一倍，……，第i+1个队列的时间片要比第i个队列的时间片长一倍。

(2)  当一个新进程进入内存后，首先将它放入第一队列的末尾，按FCFS原则排队等待调度。当轮到该进程执行时，如它能在该时间片内完成，便可准备撤离系统；如果它在一个时间片结束时尚未完成，调度程序便将该进程转入第二队列的末尾，再同样地按FCFS原则等待调度执行；如果它在第二队列中运行一个时间片后仍未完成，再依次将它放入第三队列，……，如此下去，当一个长作业(进程)从第一队列依次降到第*n*队列后，在第*n* 队列便采取按时间片轮转的方式运行。

(3)  仅当第一队列空闲时，调度程序才调度第二队列中的进程运行；仅当第1～(i-1)队列均空时，才会调度第i队列中的进程运行。如果处理机正在第i队列中为某进程服务时，又有新进程进入优先权较高的队列(第1～(i-1)中的任何一个队列)，则此时新进程将抢占正在运行进程的处理机，即由调度程序把正在运行的进程放回到第i队列的末尾，把处理机分配给新到的高优先权进程。 

### 进程有哪几种状态？             

1、就绪状态：进程已获得除处理机以外的所需资源，等待分配处理机资源
2、运行状态：占用处理机资源运行，处于此状态的进程数小于等于CPU数
3、阻塞状态： 进程等待某种条件，在条件满足之前无法执行 

### 进程的通信方式有哪些？             

``` 题库&gt;基础知识&gt;操作系统
主要分为：管道、系统IPC（包括消息队列、信号量、共享存储）、SOCKET

管道主要分为：普通管道PIPE 、流管道（s_pipe）、命名管道（name_pipe）

1、管道是一种半双工的通信方式，数据只能单项流动，并且只能在具有亲缘关系的进程间流动，进程的亲缘关系通常是父子进程
2、命名管道也是半双工的通信方式，它允许无亲缘关系的进程间进行通信
3、信号量是一个计数器，用来控制多个进程对资源的访问，它通常作为一种锁机制。
4、消息队列是消息的链表，存放在内核中并由消息队列标识符标识。
5、信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。
6、共享内存就是映射一段能被其它进程访问的内存，这段共享内存由一个进程创建，但是多个进程可以访问。
```

### 线程同步的方式有哪些？             

 	1、互斥量：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。 

 	 2、信号量：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。  

 	3、事件（信号）：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作。 

解析：

首先要明白，什么是线程同步，为什么要同步？

 所谓同步，就是并发的线程在一些关键点上可能需要互相等待与互通信息，这种相互制约的等待与互通信息称为进程同步。

 “同”其实是协同，而不是同时，因为我们知道多线程终究是不能同时执行的（看起来那么多程序同时运行互相不干扰那是从宏观层面看是这样），那么线程之间由于执行权在不断地切换，如果不同线程都做不同的事，处理不同的数据倒也没什么问题，关键是有时候会有那么一些数据，是被多个线程共享的，大家都有可能对这些数据进行一些操作。

 比如，银行系统同时收到两个请求向同一个账户A存钱，都是要存入100元.账户A中本来有1000元。那么系统对两个请求肯定是分别生成一个线程去完成各自的对账户进行加上100元的操作，可是当其中一个线程1运行完以下语句：

 account=account+100 

 当线程1读取到account在内存中的值1000并加上了100得到1100，但还没更新到数据库中时，线程1由于丧失了执行权，线程2来接手了，线程2也执行这一句，但它读到的account值依然是1000（数据库的数据尚未更新），也把它加上100，变成1100，然后要更新到数据库。那后面不管谁先更新到数据库，数据库里A账户的记录都只会是1100，而不是1200了，这就出岔子了。

 要防范这种问题也不难，我们可以让给执行账户值更改一直到把新的值更新到数据库里的整个操作给”封闭“起来，一次只允许一个线程来对同一个账户执行这样一些操作，如果多个线程想同时来执行这个操作，对不起，因为这些操作被”封闭“了，不等里面的一个线程把它要做的修改更新到数据库之前，其它线程一概不许进入，乖乖在外面排队等着吧。

 这只是一个简单的例子，于是我们需要一些机制来保证这样的问题不会出现，让不同的线程在操作这样一些共同的数据时不会出问题，再或者是有时候有些事必须等A线程做完了，B线程才能接着后面的做，我们要让这些需要多个线程合作的任务都正常进行，因此就要让它们”同步“！

这里再引入一个临界资源与临界区的概念：

 临界资源是指一次仅允许一个线程使用的资源，许多物理设备，如打印机都有这种性质。除了物理设备外，还有一些软件资源，若被多线程所共享也具有这一特点，如变量、数据、表格、队列等。它们虽可以为若干线程所共享，但一次只能为一个线程所利用。

 	临界区指的是一个访问共用资源（被多个线程共享的临界资源）的程序片段，而这些共用资源又无法同时被多个线程访问的特性。当有线程进入临界区段时，其他线程或是进程必须等待（例如：bounded  waiting  等待法），有一些同步的机制必须在临界区段的进入点与离开点实现，以确保这些共用资源是被互斥获得使用，例如：semaphore。只能被单一线程访问的设备，例如：打印机。 

 	


 如上所述，同步机制所要解决的绝大多数问题，都出在临界区这儿，我们后面的同步机制都是在临界区上做文章，以避免出现问题。

同步有以下这样些个方式/机制：

 （1）互斥量(mutex)：互斥量是一种公共资源，在指定时刻，它只能被一个线程占有（也就是所有权特性），而且占有它的线程可以反复申请这个互斥量。只有拥有互斥量的线程才有访问公共资源的权限。因为互斥量只有一个，所以可以保证公共资源不会被多个线程同时访问。（比如Java中的synchronized代码块，需要你提供一个类的对象或Class类作为锁，这个锁就可以理解为互斥量）

 （2）信号量(semaphore)：每个信号量都是公共资源，其值是一个32位计数。信号量的数据结构为一个值和一个指针，指针指向等待该信号量的下一个进程。信号量的值与相应资源的使用情况有关。当它的值大于0时，表示当前可用资源的数量；当它的值小于0时，其绝对值表示等待使用该资源的进程个数。注意，信号量的值仅能由PV操作来改变。

 实现的P，V操作算法描述：

 P操作：while s>0

 s=s-1，

 V操作：s=s+1。

 P表示申请一个资源，如果条件满足（即右可以分配的资源），则把资源分配给提出申请的进程，并且时资源数目s减1。V表示资源使用哪完毕之后，要把占有的资源释放，并且资源数目s加1 。

 （3）事件（信号 signal）：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作。（比如Java中的notify（）唤醒wait（）状态的阻塞线程）

### **解决死锁的方法有：** 

- 预防死锁：通过设置某些限制条件，去破坏产生死锁的四个必要条件中的一个或几个条件，来防止死锁的发生。

- 避免死锁：在资源的动态分配过程中，用某种方法去防止系统进入不安全状态，从而避免死锁的发生。
  检测死锁：允许系统在运行过程中发生死锁，但可设置检测机构及时检测死锁的发生，并采取适当措施加以清除。

- 解除死锁：当检测出死锁后，便采取适当措施将进程从死锁状态中解脱出来。

 	### **解决死锁的策略有：** 

 	鸵鸟策略、预防策略、避免策略、检测与解除死锁 



### **什么是死锁：** 

 	在两个或者多个并发进程中，如果每个进程持有某种资源而又等待其它进程释放它或它们现在保持着的资源，在未改变这种状态之前都不能向前推进，称这一组进程产生了死锁。通俗的讲就是两个或多个进程无限期的阻塞、相互等待的一种状态。 

### **死锁产生的四个必要条件：**  

 	（有一个条件不成立，则不会产生死锁） 

 	1、互斥条件：一个资源一次只能被一个进程使用 

 	2、请求与保持条件：一个进程因请求资源而阻塞时，对已获得资源保持不放 

 	3、不剥夺条件：进程获得的资源，在未完全使用完之前，不能强行剥夺 

 	4、循环等待条件：若干进程之间形成一种头尾相接的环形等待资源关系 



###      分页和分段有什么区别？             

 	1、段是信息的逻辑单位，它是根据用户的需要划分的，因此段对用户是可见的 ；页是信息的物理单位，是为了管理主存的方便而划分的，对用户是透明的。 

 	2、段的大小不固定，有它所完成的功能决定；页大大小固定，由系统决定 

 	3、段向用户提供二维地址空间；页向用户提供的是一维地址空间 

 	4、段是信息的逻辑单位，便于存储保护和信息的共享，页的保护和共享受到限制。 





###  什么是缓冲区溢出？有什么危害？

 	缓冲区溢出是指当计算机向缓冲区填充数据时超出了缓冲区本身的容量，溢出的数据覆盖在合法数据上。 

 	危害有以下两点： 

 	（1）程序崩溃，导致拒绝额服务 

 	（2）跳转并且执行一段恶意代码 

 	造成缓冲区溢出的主要原因是程序中没有仔细检查用户输入。 

### 堆和栈的区别

栈：函数参数、返回地址、局部变量（运行入口知道大小）
1. 编译器自动分配释放，存放函数的参数值，局部变量的值等。
2. 申请后的响应：若栈的剩余空间大于申请空间，系统将为程序提供内存，否则提示栈溢出
3. 大小限制：向低地址扩展，连续的内存区域，栈顶地址和栈最大容量是系统事先规定好的。如果申请的空间超过栈的剩余空间将栈溢出
4. 申请效率：系统自动分配，速度快，程序员无法控制
5. 存储的内容：函数调用时进栈顺序：主函数下一条指令的地址（函数调用语句的下一条可执行语句）、函数的各个参数（大多数c编译器中参数是从右往左入栈）、函数的局部变量。
    调用结束的出栈顺序：局部变量、函数参数（从左到右）、栈顶指针指向最开始存的地址（即主函数的下一条指令）

堆：运行期间动态分配的内存空间（运行的时候才知道大小）
1. 程序员自己分配释放，分配方式类似于链表
2. 申请后的响应：操作系统有一个记录空闲内存地址的链表，当系统收到程序的申请时会遍历该链表，寻找第一个空间大于所申请空间的堆结点，将该结点从空闲结点链表删除，分配该结点的空间给程序。会在这块内存空间中的首地址处记录本次分配的大小。
    这样delete语句才能正确释放本内存空间。由于找到的堆结点的大小不一定正好等于申请的大小，系统会自动将多余的那部分重新放入空闲链表中
3. 大小限制：向高地址扩展，不连续的内存区域，用链表存储，遍历方向是由低地址向高地址。堆大小受限于计算机系统的有效虚拟内存。获得的空间更大更灵活
4. 申请效率：用new分配，速度慢，容易产生内部碎片，使用方便
5. 存储的内容：一般在堆的头部用一个字节放堆的大小

